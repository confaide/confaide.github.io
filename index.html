<!DOCTYPE html>
<html>
  <style>
    head {
       background-color: rgb(9,8,51);
       color: white;
    }
    body {
       background-color: rgb(9,8,51);
       color: white;
    }
 </style>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Contextual Privacy in LLMs">
  <meta name="keywords" content="confAIde, privacy, LLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title style="color: white">Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><b style="font-family:Courier new; ">ConfAIde</b>: Can LLMs Keep a Secret? Testing Privacy Implications<br>of Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://cseweb.ucsd.edu/~fmireshg/">Niloofar Mireshghallah</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://hyunw.kim">Hyunwoo Kim</a><sup>2*</sup>,</span><br>
            <span class="author-block">
              <a href="https://xuhuiz.com">Xuhui Zhou</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~yuliats/">Yulia Tsvetkov</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://maartensap.com">Maarten Sap</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.comp.nus.edu.sg/~reza/">Reza Shokri</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington</span>
            <span class="author-block"><sup>2</sup>Allen Institute for Artificial Intelligence</span><br>
            <span class="author-block"><sup>3</sup>Carnegie Mellon University</span>
            <span class="author-block"><sup>4</sup>National University of Singapore</span>
            <span class="author-block"><sup>*</sup>Equal Contribution</span>

          </div>
        </br>
          <!--Centered Image Start-->
          <div style="text-align: center;">
            <img src="./static/images/fig.png" alt="" style="width:35%;height:35%;" class="center">
            <figcaption style="font-size: small;">Image credit: <a href="https://www.bing.com/create">Bing Image Creator</a></figcaption>
            <!-- <figcaption style="font-size: small;">Image credit: <a href="https://www.bing.com/create">Bing Image Creator</a> and <a href="https://en.wikipedia.org/wiki/To_be,_or_not_to_be">Shakespeare's Hamlet</a></figcaption> -->
          </figure>          
        </div>
          <!--Centered Image End-->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/skywalker023/confAIde"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/skywalker023/confAIde/benchmark"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->

<!--
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="color: white;">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and we expect them to reason about what to share in their outputs, for what purpose and with whom, in a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing <em style="font-family:Courier new; ">ConfAIde</em>, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory of mind.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Tier Structure. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="color: white;"><em style="font-family:Courier new; ">ConfAIde</em>: Benchmarking Contextual Privacy Reasoning in LLMs</h2>
          <!--Centered Image Start-->
          <div style="text-align: center;">
            <img src="./static/images/fig-website-tier.png" alt="" style="width:100%;height:100%;" class="center">
            <figcaption style="font-size: small;">Tiered structure of our <em style="font-family:Courier new; ">ConfAIde</em> benchmark.</figcaption>
          </figure>          
        </div>
          <!--Centered Image End-->
        <div class="content has-text-justified">
          <p>
          </br>
            Our benchmark consists of four tiers, each with distinct evaluation tasks.
          </br>
          </br>
          
            <b>Tier 1 (Info-Sensitivity)</b>:  assesses LLMs on their ability to understand the sensitivity of given information, using ten predefined information types.
            </br>
          </br>
            <b>Tier 2 (InfoFlow-Expectation)</b>:  evaluates models' expectations of information flow using vignettes based on three contextual factors: information type, actor, and use. This tier includes two sub-tiers: Tier 2.a and Tier 2.b, with Tier 2.b expanding vignettes into short stories.
            </br>
          </br>
            <b>Tier 3 (InfoFlow-Control)</b>:  tests the model's ability to control the flow of private information within complex scenarios involving three parties. It requires social reasoning skills, such as theory of mind.
            </br>
          </br>
            <b>Tier 4 (InfoFlow-Application)</b>:  examines privacy reasoning in real-world scenarios, specifically in automatic action-item and summary generation from meeting transcripts.
            </br>
          </br>
            Each tier has a specific design and evaluation focus, ranging from basic information sensitivity to more complex real-world applications.
          </p>
        </div>
      </div>
    </div>
    <!-- Tier Structure. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="color: white;">Result Highlights</h2>
          <!--Centered Image Start-->
          <div style="text-align: center;">
            <img src="./static/images/results-tier-1-2.png" alt="" style="width:100%;height:100%;" class="center">
            <figcaption style="font-size: small;">Breakdown of GPT-4 judgment over contextual factors, as we progress through tiers 1, 2.a and 2.b.</figcaption>
          </figure>          
        </div>
          <!--Centered Image End-->
        <div class="content has-text-justified">
        </br>
          <p>
            <b>Effect of actor and use on privacy expectations (tiers 1-2.b).</b> The figure above shows how GPT-4's judgment varies based on different contextual factors and data sensitivity, progressing through tiers 1, 2.a and 2.b. For example, the sensitivity of sharing Social Security Numbers (SSN) decreases when it's shared with insurance (Tier 2.a) instead of being highly sensitive (Tier 1). The figure also shows that sharing SSN with a doctor becomes less of a privacy concern when moving from Tier 2.a to 2.b with GPT-4. 
          </p>
        </div>
          <!--Centered Image Start-->
          <div style="text-align: center;">
            <img src="./static/images/plots.png" alt="" style="width:100%;height:100%;" class="center">
            <figcaption style="font-size: small;">Summary of Tier 3 and Tier 4 leakage percentage results: State of the art models (GPT-4 and ChatGPT) leak secrets at an alarming rate, and using chain of thought reasoning doesn't help!</figcaption>
          </figure>          
        </div>
      </br>
          <!--Centered Image End-->
        <div class="content has-text-justified">
          <p>
            <b>High levels of leakage in theory of mind based scenarios.</b> The figures above show the worst case leakage of ChatGPT and GPT-4 on Tiers 3 and 4 scenarios, where we ask the model to finish a story or to summarize a work meeting. We can see that the leakage of both models is alarmingly high, although we are using a privacy-inducing prompt which instructs the model to consider privacy norms before responding.
          </br>
        </br>
          <b>Does CoT reasoning help?</b> To see if patching solutions work we use chain of thought reasoning and ask the model to think step by step. We observe that even CoT doesn't improve leakage, in fact it makes it slightly worse, underscoring the need for fundamental solutions!
          </p>
        </div>
      </div>
    </div>
    <!-- Results. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Next. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="color: white;">So What's Next?</h2>
        <div class="content has-text-justified">
          <p>
          </br>
            <b>Inference-Time Privacy Definitions:</b> Current research highlights a crucial gap in privacy definitions during the inference phase, which has significant implications. For instance, a recent attack exposed vulnerabilities in Bing Chat's initial prompt, affecting its interactions with users. We emphasize the need to address changes in model deployment and usage, particularly in interactive applications, and acknowledge the existence of various unexplored privacy concerns. These include the potential leakage of in-context examples to the model's output and conflicts between different data types in multi-modal models.
          </br> </br>
            <b>Fundamental Privacy Solutions:</b> We demonstrate the complexity of addressing these issues and argue that ad hoc solutions like privacy-inducing prompts and output filters are insufficient for addressing the core challenge of contextual privacy reasoning. Prior efforts to mitigate biases and hallucinations in language models have shown that such safeguards can be easily bypassed by malicious inputs. To address these concerns, we advocate for fundamental and principled inference-time approaches, such as utilizing explicit symbolic graphical representations of individuals' beliefs to enhance decision-making while considering privacy and information flow.
          </br> </br>
            <b>Secret Disclosure and Moral Incentives:</b> While our benchmark assesses models for their privacy reasoning abilities based on the theory of contextual integrity, we do not aim to dictate privacy standards or make normative judgments, as these judgments are intertwined with moral and cultural factors in interactions. Social psychologists have studied the moral incentives behind disclosing others' secrets as a form of punishment. We encourage further research into these incentives within language models.
        </p>
        </div>
      </div>
    </div>
    <!-- Next. -->
  </div>
</section>

    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX" style="background-color: rgb(9,8,51);">
  <div class="container is-max-desktop content" style="background-color: rgb(9,8,51);">
    <h2 class="title" style="color: white;">BibTeX</h2>
    <pre style="background-color: rgb(54,54, 54); color: white;"><code >@article{confaide2023,
  author    = {Mireshghallah, Niloofar and Kim, Hyunwoo and Zhou, Xuhui  and Tsvetkov, Yulia and Sap, Maarten and Shokri, Reza and Choi, Yejin},
  title     = {Can LLMs Keep a Secret? Testing Privacy  Implications of Language Models via Contextual Integrity Theory},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <!-- <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
